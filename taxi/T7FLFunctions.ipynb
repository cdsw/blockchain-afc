{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from T4MLTraining import *\n",
    "from tensorflow.python.keras.models import clone_model\n",
    "from copy import deepcopy"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-13 12:04:50.175385: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-13 12:04:50.175412: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Client:\n",
    "    def __init__(self, id_, inp_train, out_train, inp_test, out_test):\n",
    "        self.id_ = id_\n",
    "        self.inp_train = inp_train\n",
    "        self.out_train = out_train\n",
    "        self.inp_test = inp_test\n",
    "        self.out_test = out_test\n",
    "        self.deviation = 1\n",
    "\n",
    "    def getWeight(self):\n",
    "        return sum(flatten(self.inp_train.tolist()[0]))\n",
    "        \n",
    "    def extract(self):\n",
    "        return self.inp_train, self.out_train, self.inp_test, self.out_test\n",
    "    \n",
    "    def setModel(self, model):\n",
    "        model_copy = clone_model(model.model)\n",
    "        #model_copy.build((None, len(self.inp_train[0]), 1))\n",
    "        model_copy.compile(optimizer='adam', loss='mse')\n",
    "        model_copy.set_weights(model.model.get_weights())\n",
    "        model = deepcopy(model)\n",
    "        model.model = model_copy\n",
    "        self.model = model\n",
    "        self.model.setData(self.inp_train, self.out_train)\n",
    "\n",
    "    def train(self, draw_loss=False):\n",
    "        ts = time.time()\n",
    "        self.model.train()\n",
    "        te = time.time()\n",
    "        print(\"Cli# {0}: {1:.2f} sec\".format(self.id_, te - ts), end = '; ')\n",
    "        if draw_loss == True:\n",
    "            self.model.drawLoss()\n",
    "\n",
    "    def extractModel(self):\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, frame_in, frame_out, verbose_=False):\n",
    "        predictor = Prediction(self.inp_test,self.out_test,self.model, frame_in, frame_out)\n",
    "        predictor.predict()\n",
    "        predictor.summary(\"\",verbose_)\n",
    "        self.deviation = predictor.in_percent / 100\n",
    "        return self.deviation\n",
    "\n",
    "class Distributor:\n",
    "    def __init__(self, dat, company, location, div_company=True, div_location=False, bin_='40T', frame_out=2, ratio=0.8):\n",
    "        self.dat = dat\n",
    "        self.company = company\n",
    "        self.location = location\n",
    "        self.divide_by_company = div_company\n",
    "        self.divide_by_location = div_location # NOT YET IMPLEMENTED\n",
    "        self.clients = []\n",
    "        \n",
    "        self.bin_=bin_\n",
    "        self.frame_out = frame_out\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def divByCompany(self):\n",
    "        for c in self.company:\n",
    "            tr = DataPrep(self.dat,[c],self.location,[c],self.location,self.bin_,self.frame_out,self.ratio)\n",
    "            tr.setup()\n",
    "\n",
    "            inp_train, out_train, inp_test, out_test = tr.extract()\n",
    "            cli = Client(str(c), inp_train, out_train, inp_test, out_test)\n",
    "            self.clients.append(cli)\n",
    "    \n",
    "    def extractClients(self):\n",
    "        return self.clients\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def weighting(model, wei):\n",
    "    for i in range(len(model)):\n",
    "        model[i] *= wei\n",
    "    return model\n",
    "\n",
    "def combine_models(m1, m2):\n",
    "    m = deepcopy(m1)\n",
    "    for i in range(len(m1)):\n",
    "        m[i] += m2[i]\n",
    "    return m"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Server:\n",
    "    def __init__(self, clients, frame_in, frame_out, model_type, epochs_):\n",
    "        self.clients = clients\n",
    "        self.cli_models = []\n",
    "        if model_type == 'CNNLSTM':\n",
    "            self.model = CNNLSTM(frame_in, frame_out, epochs=epochs_)\n",
    "        self.frame_in = frame_in\n",
    "        self.frame_out = frame_out\n",
    "\n",
    "    def askClients(self):\n",
    "        for c in self.clients:\n",
    "            c.train()\n",
    "            m = c.extractModel()\n",
    "            self.cli_models.append(m)      \n",
    "\n",
    "    def aggregate(self, mode='amt'):\n",
    "        multiplier = []\n",
    "        cli_weights = []\n",
    "        # get client demand size and weights\n",
    "        for c in self.clients:\n",
    "            if mode == 'amt':\n",
    "                w = c.getWeight()\n",
    "            elif mode == 'pre':\n",
    "                w = c.predict(self.frame_in, self.frame_out, verbose_=0)\n",
    "                try:\n",
    "                    w = (1 / w)\n",
    "                except ZeroDivisionError:\n",
    "                    w = 1\n",
    "            multiplier.append(w)\n",
    "            cli_weights.append(c.model.model.get_weights())\n",
    "        total_multiplier = sum(multiplier)\n",
    "\n",
    "        # get proportions\n",
    "        multiplier_proportion = []\n",
    "        for w in multiplier:\n",
    "            multiplier_proportion.append(w/total_multiplier)\n",
    "        \n",
    "        # averaging\n",
    "        average = None\n",
    "        for i in range(len(cli_weights)):\n",
    "            weighted = weighting(cli_weights[i],multiplier_proportion[i])\n",
    "            if average == None:\n",
    "                average = weighted\n",
    "            else:\n",
    "                average = combine_models(average, weighted)\n",
    "\n",
    "        # repacking in global model\n",
    "        self.model.model.set_weights(average)\n",
    "        self.model.model.build((None,self.frame_in,1))\n",
    "        self.model.model.compile(optimizer='adam',loss='mse')\n",
    "\n",
    "    def sendGlobalModel(self):\n",
    "        for c in clients:\n",
    "            c.setModel(self.model)\n",
    "\n",
    "    def iterate(self, iters, mode='amt'):\n",
    "        for i in range(iters):\n",
    "            print(\"\\nIteration \" + str(i + 1) + \" of \" + str(iters), end=' | ')\n",
    "            tsg = time.time()\n",
    "            self.sendGlobalModel() # loop start\n",
    "            tsh = time.time()\n",
    "            self.askClients()\n",
    "            tsi = time.time()\n",
    "            self.aggregate(mode)\n",
    "            tsj = time.time()\n",
    "            print(\" | Glob: {0:.2f}s, Train: {1:.2f}s, Aggr: {2:.2f}s.\".format(tsh-tsg, tsi-tsh, tsj-tsi))\n",
    "        return self"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Builder\n",
    "dat = 'trips_simpler.csv'\n",
    "bin_ = '40T'\n",
    "company = [2,3,4,5]\n",
    "location = [mk for mk in range(9)]\n",
    "frame_in = binToWindows(bin_)\n",
    "frame_out = 2\n",
    "ratio = 0.8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Distribute data to clients\n",
    "db = Distributor(dat, company, location)\n",
    "db.divByCompany()\n",
    "clients = db.extractClients()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2] [0, 1, 2, 3, 4, 5, 6, 7, 8] | Sum of all datalist: 596314 | Sum of all tested: 118692\n",
      "[3] [0, 1, 2, 3, 4, 5, 6, 7, 8] | Sum of all datalist: 12732738 | Sum of all tested: 2738413\n",
      "[4] [0, 1, 2, 3, 4, 5, 6, 7, 8] | Sum of all datalist: 851726 | Sum of all tested: 177922\n",
      "[5] [0, 1, 2, 3, 4, 5, 6, 7, 8] | Sum of all datalist: 4201065 | Sum of all tested: 893440\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Server simulation\n",
    "epochs = 2000\n",
    "iterations = 1\n",
    "serv = Server(clients, frame_in, frame_out, 'CNNLSTM', epochs_=int(epochs/iterations))\n",
    "serv.iterate(iterations, mode='pre')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-13 12:05:57.477628: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-13 12:05:57.477660: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-13 12:05:57.477679: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cl): /proc/driver/nvidia/version does not exist\n",
      "2021-08-13 12:05:57.477849: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Iteration 1 of 2 | "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-13 12:05:58.239754: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-13 12:05:58.240444: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2592000000 Hz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cli# 2: 201.42 sec; Cli# 3: 207.38 sec; Cli# 4: 215.92 sec; Cli# 5: 211.55 sec;  | Glob: 0.56s, Train: 836.28s, Aggr: 27.95s.\n",
      "\n",
      "Iteration 2 of 2 | Cli# 2: 208.62 sec; Cli# 3: 208.99 sec; Cli# 4: 1909.48 sec; Cli# 5: 160.48 sec;  | Glob: 0.52s, Train: 2487.57s, Aggr: 20.39s.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.Server at 0x7fd8c8dd8c40>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for c in serv.clients:\n",
    "    c.predict(frame_in,frame_out, verbose_=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE  = 45\n",
      "Total demand  = [118692]\n",
      "Average demand  = 567\n",
      "Deviation  = [7.96]%\n",
      "RMSE  = 574\n",
      "Total demand  = [2738413]\n",
      "Average demand  = 13102\n",
      "Deviation  = [4.38]%\n",
      "RMSE  = 44\n",
      "Total demand  = [177922]\n",
      "Average demand  = 851\n",
      "Deviation  = [5.24]%\n",
      "RMSE  = 229\n",
      "Total demand  = [893440]\n",
      "Average demand  = 4274\n",
      "Deviation  = [5.37]%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}